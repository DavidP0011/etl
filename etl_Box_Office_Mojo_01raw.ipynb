{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmwIwtyNqd9Nj3LBtkdI/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidP0011/etl/blob/main/etl_Box_Office_Mojo_01raw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RrWksRzKrJyY"
      },
      "outputs": [],
      "source": [
        "# Instalación de bibliotecas necesarias\n",
        "# !pip install requests beautifulsoup4 pandas google-cloud-bigquery\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "import re\n",
        "import time\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "def scrape_and_upload_with_tconst(config):\n",
        "    \"\"\"\n",
        "    Función para scrapear datos de Box Office Mojo y agregar el tconst desde IMDb Pro,\n",
        "    luego subir los datos a Google BigQuery.\n",
        "\n",
        "    Args:\n",
        "        config (dict): Configuración de la función.\n",
        "            - \"project_id\" (str): ID del proyecto en Google Cloud.\n",
        "            - \"dataset_id\" (str): ID del conjunto de datos en BigQuery.\n",
        "            - \"table_id\" (str): Nombre de la tabla en BigQuery.\n",
        "            - \"start_year\" (int): Año inicial del rango.\n",
        "            - \"end_year\" (int): Año final del rango.\n",
        "            - \"truncate_table\" (bool): Si es True, truncar la tabla antes de subir los datos.\n",
        "            - \"log_file\" (str): Ruta al archivo de log (opcional).\n",
        "    \"\"\"\n",
        "    # Configuración del logger\n",
        "    logger = logging.getLogger('BoxOfficeScraper')\n",
        "    logger.setLevel(logging.DEBUG)  # Establece el nivel mínimo de log\n",
        "\n",
        "    # Crear manejador para consola\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.INFO)  # Nivel de log para la consola\n",
        "\n",
        "    # Crear manejador para archivo (si se especifica)\n",
        "    if 'log_file' in config:\n",
        "        fh = logging.FileHandler(config['log_file'])\n",
        "        fh.setLevel(logging.DEBUG)  # Nivel de log para el archivo\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        fh.setFormatter(formatter)\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    # Formateador para la consola\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    ch.setFormatter(formatter)\n",
        "\n",
        "    # Añadir manejadores al logger\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    # Configuración del cliente BigQuery\n",
        "    client = bigquery.Client(project=config[\"project_id\"])\n",
        "\n",
        "    # Función interna para scrapeo de la tabla principal\n",
        "    def scrape_box_office(year):\n",
        "        url = f\"https://www.boxofficemojo.com/year/world/{year}/\"\n",
        "        logger.info(f\"Accediendo a la URL: {url}\")\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "            logger.debug(f\"Respuesta HTTP obtenida para el año {year}.\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"Error al acceder a la página para el año {year}: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Buscar la tabla principal\n",
        "        table = soup.find(\"table\")\n",
        "        if not table:\n",
        "            logger.warning(f\"No se encontró la tabla para el año {year}.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Extraer encabezados para mapear columnas dinámicamente\n",
        "        headers = [header.text.strip() for header in table.find_all(\"th\")]\n",
        "        logger.debug(f\"Encabezados de la tabla para {year}: {headers}\")\n",
        "\n",
        "        # Mapeo de columnas basado en los encabezados actuales\n",
        "        try:\n",
        "            rank_idx = headers.index(\"Rank\")\n",
        "            title_idx = headers.index(\"Release Group\")\n",
        "            worldwide_gross_idx = headers.index(\"Worldwide\")\n",
        "            domestic_gross_idx = headers.index(\"Domestic\")\n",
        "            international_gross_idx = headers.index(\"Foreign\")\n",
        "        except ValueError as ve:\n",
        "            logger.error(f\"Error al encontrar índices de columnas: {ve}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        rows = table.find_all(\"tr\")[1:]  # Ignorar el encabezado\n",
        "\n",
        "        # Procesar filas\n",
        "        data = []\n",
        "        total_rows = len(rows)\n",
        "        logger.info(f\"Procesando {total_rows} filas para el año {year}...\")\n",
        "        for idx, row in enumerate(rows, start=1):\n",
        "            cols = row.find_all(\"td\")\n",
        "            if len(cols) < max(rank_idx, title_idx, worldwide_gross_idx, domestic_gross_idx, international_gross_idx) + 1:\n",
        "                logger.debug(f\"Fila {idx} ignorada por tener columnas insuficientes.\")\n",
        "                continue\n",
        "\n",
        "            # Verificar si la primera columna es un número (Rank)\n",
        "            rank_text = cols[rank_idx].text.strip()\n",
        "            if not rank_text.isdigit():\n",
        "                logger.debug(f\"Fila {idx} ignorada porque 'Rank' no es un número: '{rank_text}'\")\n",
        "                continue  # Saltar filas donde el Rank no es un número\n",
        "\n",
        "            try:\n",
        "                rank = int(rank_text)\n",
        "                title = cols[title_idx].text.strip()\n",
        "                title_link = cols[title_idx].find(\"a\")[\"href\"]\n",
        "\n",
        "                # Función interna para parsear valores de ganancias\n",
        "                def parse_gross(text):\n",
        "                    text = text.strip().replace(\"$\", \"\").replace(\",\", \"\").replace(\"--\", \"\").replace(\"-\", \"\")\n",
        "                    if text in [\"\", \"--\", \"-\"]:\n",
        "                        return None\n",
        "                    # Manejar posibles rangos o valores no numéricos\n",
        "                    match = re.match(r'^\\d+$', text)\n",
        "                    return int(text) if match else None\n",
        "\n",
        "                # Extraer y parsear las ganancias\n",
        "                domestic_text = cols[domestic_gross_idx].text.strip()\n",
        "                foreign_text = cols[international_gross_idx].text.strip()\n",
        "                logger.debug(f\"Fila {idx}: Domestic='{domestic_text}', Foreign='{foreign_text}'\")\n",
        "\n",
        "                worldwide_gross = parse_gross(cols[worldwide_gross_idx].text)\n",
        "                domestic_gross = parse_gross(domestic_text)\n",
        "                international_gross = parse_gross(foreign_text)\n",
        "\n",
        "                # Agregar los datos al listado\n",
        "                data.append({\n",
        "                    \"Year\": year,\n",
        "                    \"Rank\": rank,\n",
        "                    \"Title\": title,\n",
        "                    \"Worldwide_Gross\": worldwide_gross,\n",
        "                    \"Domestic_Gross\": domestic_gross,\n",
        "                    \"International_Gross\": international_gross,\n",
        "                    \"Detail_Link\": f\"https://www.boxofficemojo.com{title_link}\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error procesando una fila en el índice {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Añadir retraso entre filas para evitar sobrecargar el servidor\n",
        "            time.sleep(0.1)  # Esperar 100ms\n",
        "\n",
        "        logger.info(f\"Procesadas {len(data)} filas válidas para el año {year}.\")\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    # Función interna para obtener el tconst de IMDb Pro desde la página de detalles\n",
        "    def get_tconst(detail_link):\n",
        "        logger.debug(f\"Obteniendo tconst desde: {detail_link}\")\n",
        "        try:\n",
        "            response = requests.get(detail_link)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "            # Buscar el enlace a IMDb Pro\n",
        "            imdb_link = soup.find(\"a\", href=lambda href: href and \"pro.imdb.com/title\" in href)\n",
        "            if imdb_link:\n",
        "                tconst_match = re.search(r'/title/(tt\\d+)/', imdb_link[\"href\"])\n",
        "                if tconst_match:\n",
        "                    tconst = tconst_match.group(1)\n",
        "                    logger.debug(f\"tconst encontrado: {tconst}\")\n",
        "                    return tconst\n",
        "            logger.warning(f\"tconst no encontrado en: {detail_link}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"Error al acceder al detalle: {detail_link} - {e}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error al procesar el detalle: {detail_link} - {e}\")\n",
        "        return None\n",
        "\n",
        "    # Scrapear datos para cada año en el rango\n",
        "    all_data = pd.DataFrame()\n",
        "    for year in range(config[\"start_year\"], config[\"end_year\"] + 1):\n",
        "        logger.info(f\"Scraping data for {year}...\")\n",
        "        year_data = scrape_box_office(year)\n",
        "\n",
        "        if year_data.empty:\n",
        "            logger.warning(f\"No se encontraron datos para el año {year}.\")\n",
        "            continue\n",
        "\n",
        "        # Agregar tconst a cada fila\n",
        "        logger.info(\"Fetching IMDb tconst for each title...\")\n",
        "        year_data[\"tconst\"] = year_data[\"Detail_Link\"].apply(get_tconst)\n",
        "\n",
        "        # Reportar cuántos tconst se encontraron\n",
        "        tconst_found = year_data[\"tconst\"].notnull().sum()\n",
        "        tconst_total = len(year_data)\n",
        "        logger.info(f\"tconst encontrados: {tconst_found}/{tconst_total}\")\n",
        "\n",
        "        all_data = pd.concat([all_data, year_data], ignore_index=True)\n",
        "\n",
        "    if all_data.empty:\n",
        "        logger.error(\"No hay datos para subir a BigQuery.\")\n",
        "        return\n",
        "\n",
        "    # Definir el esquema de BigQuery\n",
        "    schema = [\n",
        "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
        "        bigquery.SchemaField(\"Rank\", \"INTEGER\"),\n",
        "        bigquery.SchemaField(\"Title\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Worldwide_Gross\", \"INTEGER\"),\n",
        "        bigquery.SchemaField(\"Domestic_Gross\", \"INTEGER\"),\n",
        "        bigquery.SchemaField(\"International_Gross\", \"INTEGER\"),\n",
        "        bigquery.SchemaField(\"Detail_Link\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"tconst\", \"STRING\"),\n",
        "    ]\n",
        "\n",
        "    # Convertir las columnas de ganancias a tipo integer (ya se hizo en parse_gross)\n",
        "    # Verificar tipos de datos\n",
        "    expected_types = {\n",
        "        \"Year\": int,\n",
        "        \"Rank\": int,\n",
        "        \"Title\": str,\n",
        "        \"Worldwide_Gross\": pd.Int64Dtype(),\n",
        "        \"Domestic_Gross\": pd.Int64Dtype(),\n",
        "        \"International_Gross\": pd.Int64Dtype(),\n",
        "        \"Detail_Link\": str,\n",
        "        \"tconst\": str,\n",
        "    }\n",
        "\n",
        "    for column, dtype in expected_types.items():\n",
        "        if column in all_data.columns:\n",
        "            all_data[column] = all_data[column].astype(dtype)\n",
        "        else:\n",
        "            all_data[column] = None  # Agregar columna si falta\n",
        "\n",
        "    # Registro de datos para depuración\n",
        "    logger.info(\"Vista previa de los datos recopilados:\")\n",
        "    logger.debug(all_data.head())\n",
        "\n",
        "    logger.info(\"Resumen de valores nulos:\")\n",
        "    logger.debug(all_data.isnull().sum())\n",
        "\n",
        "    # Subir datos a BigQuery con esquema definido\n",
        "    table_id = f\"{config['project_id']}.{config['dataset_id']}.{config['table_id']}\"\n",
        "    logger.info(f\"Uploading data to BigQuery table: {table_id}...\")\n",
        "\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        schema=schema,\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE if config.get(\"truncate_table\", False) else bigquery.WriteDisposition.WRITE_APPEND,\n",
        "        source_format=bigquery.SourceFormat.PARQUET,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        job = client.load_table_from_dataframe(all_data, table_id, job_config=job_config)\n",
        "        job.result()  # Esperar a que termine el trabajo\n",
        "        logger.info(\"Datos subidos exitosamente!\")\n",
        "        logger.info(f\"Total de registros cargados: {len(all_data)}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error al subir datos a BigQuery: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuración de ejemplo\n",
        "config = {\n",
        "    \"project_id\": \"animum-dev-datawarehouse\",   # Cambia esto por tu ID de proyecto\n",
        "    \"dataset_id\": \"BOMojo_staging_01\",   # Cambia esto por tu ID de dataset\n",
        "    \"table_id\": \"WorldwideBoxOffice_01\",         # Cambia esto por el nombre de la tabla\n",
        "    \"start_year\": 2000,                # Año inicial del rango\n",
        "    \"end_year\": 2024,                   # Año final del rango\n",
        "    \"delete_table\": True               # True para borrar los registros la tabla antes de cargar los datos\n",
        "}\n",
        "\n",
        "# Ejecutar función\n",
        "scrape_and_upload_with_tconst(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "coLtLo1uvazD",
        "outputId": "763fe754-bdd4-4485-9908-6e6d0c33eefc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-10 09:01:14,615 - INFO - Scraping data for 2000...\n",
            "2025-02-10 09:01:14,615 - INFO - Scraping data for 2000...\n",
            "INFO:BoxOfficeScraper:Scraping data for 2000...\n",
            "2025-02-10 09:01:14,622 - INFO - Accediendo a la URL: https://www.boxofficemojo.com/year/world/2000/\n",
            "2025-02-10 09:01:14,622 - INFO - Accediendo a la URL: https://www.boxofficemojo.com/year/world/2000/\n",
            "INFO:BoxOfficeScraper:Accediendo a la URL: https://www.boxofficemojo.com/year/world/2000/\n",
            "DEBUG:BoxOfficeScraper:Respuesta HTTP obtenida para el año 2000.\n",
            "DEBUG:BoxOfficeScraper:Encabezados de la tabla para 2000: ['Rank', 'Release Group', 'Worldwide', 'Domestic', '%', 'Foreign', '%']\n",
            "2025-02-10 09:01:16,223 - INFO - Procesando 200 filas para el año 2000...\n",
            "2025-02-10 09:01:16,223 - INFO - Procesando 200 filas para el año 2000...\n",
            "INFO:BoxOfficeScraper:Procesando 200 filas para el año 2000...\n",
            "DEBUG:BoxOfficeScraper:Fila 1: Domestic='$215,409,889', Foreign='$330,978,219'\n",
            "DEBUG:BoxOfficeScraper:Fila 2: Domestic='$187,705,427', Foreign='$272,878,533'\n",
            "DEBUG:BoxOfficeScraper:Fila 3: Domestic='$233,632,142', Foreign='$196,000,000'\n",
            "DEBUG:BoxOfficeScraper:Fila 4: Domestic='$182,811,707', Foreign='$191,300,000'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-41580e71089a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Ejecutar función\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mscrape_and_upload_with_tconst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-62e87b8a8ab8>\u001b[0m in \u001b[0;36mscrape_and_upload_with_tconst\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start_year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"end_year\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Scraping data for {year}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0myear_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_box_office\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0myear_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-62e87b8a8ab8>\u001b[0m in \u001b[0;36mscrape_box_office\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mtitle_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;31m# Función interna para parsear valores de ganancias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, name, attrs, recursive, string, **kwargs)\u001b[0m\n\u001b[1;32m   2706\u001b[0m         \"\"\"\n\u001b[1;32m   2707\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, attrs, recursive, string, limit, _stacklevel, **kwargs)\u001b[0m\n\u001b[1;32m   2741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2743\u001b[0;31m         return self._find_all(\n\u001b[0m\u001b[1;32m   2744\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stacklevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2745\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36m_find_all\u001b[0;34m(self, name, attrs, string, limit, generator, _stacklevel, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mResultSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;31m# These generators can be used to navigate starting from both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/filter.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, generator, limit)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \"\"\"\n\u001b[1;32m    177\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_QueryResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResultSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/filter.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, generator)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36mdescendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescendants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2763\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPageElement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m         \"\"\"Iterate over all children of this `Tag` in a\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}